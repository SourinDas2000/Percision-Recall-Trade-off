{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b46e543-efbe-4f80-b24b-e717707f1aa5",
   "metadata": {},
   "source": [
    "# Percision-Recall Trade-Off\n",
    "\n",
    "Two commonly used metrics for classification are __precision__ and __recall__. Conceptually, __precision__ refers to the percentage of positive results which are relevant, while __recall__ refers to the percentage of positive cases correctly classified. Often we face a situation where choosing between increasing the __recall__ (while lowering the __precision__) or increasing the __precision__ (and lowering the __recall__) becomes necessary. This notebook reads a popular CSV file containing the passenger list of Titanic and creates a __Logistic Regression__ model with it. The model will help to predict if a person will survive or not by analyzing other dependent variables from the CSV file. The end goal however is to increase the __precision__ of the model as much as possible, thus that all the positive predictions the model makes are correct (increased __precision__), even if it isn't able to catch all the positive predictions (lower __recall__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543590bd-0ed0-42bb-9b8b-f37158f394ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries:\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import arange, argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38211198-c85b-4244-b0b0-929b350ab089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the CSV file with pandas:\n",
    "\n",
    "df = pd.read_csv('Titanic Passenger List.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e770b-04da-43f4-8696-de236e40da3c",
   "metadata": {},
   "source": [
    "There are many text-based data (__object__) in the file. As it is difficult for a machine learning model to read and analyse anything but a numerical value, we are dropping some columns from the CSV file. Also, we are converting the \"__Sex__\" column from __strings__ to __integers__ as it is an important variable. After conversion there will be just two values denoting sex of the passengers: 0 for female and 1 for male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30049cd9-5a0d-41fc-afe8-1afc3588ed46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  male\n",
       "0         0       3  22.0      1      0   7.2500     1\n",
       "1         1       1  38.0      1      0  71.2833     0\n",
       "2         1       3  26.0      0      0   7.9250     0\n",
       "3         1       1  35.0      1      0  53.1000     0\n",
       "4         0       3  35.0      0      0   8.0500     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas 'get_dummies' function to convert strings to integeres:\n",
    "\n",
    "dummies = pd.get_dummies(df['Sex'], drop_first= True, dtype= 'int64')\n",
    "\n",
    "# The function created a new dataframe that we need to join with the original:\n",
    "\n",
    "df = pd.concat([df, dummies], axis= 'columns')\n",
    "\n",
    "# Dropping all the unnecessary columns along with the original Sex column:\n",
    "\n",
    "df = df.drop(['PassengerId', 'Name', 'Sex', \n",
    "              'Ticket', 'Cabin', 'Embarked'], axis= 'columns')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3623a21-d360-478d-99b7-f9adc3e61031",
   "metadata": {},
   "source": [
    "We need to see if there are any null values in the dataset as that could hinder our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0bb2f91-a447-45ff-b75d-06bbef5e6f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "male          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting all the null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea1c1a-8733-4e26-97e6-d4633117ab54",
   "metadata": {},
   "source": [
    "The age column has 177 null values and we need to get rid of them. To do that we will be replacing the null values with the mean age of all the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb036367-6251-4899-9c22-242a82e39a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "male        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the mean age of the passengers:\n",
    "\n",
    "mean_age = round(df['Age'].mean())\n",
    "\n",
    "# Replacing the null values with the mean age:\n",
    "\n",
    "df['Age'] = df['Age'].fillna(mean_age)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153b6e9-3810-4491-8d83-30b4e0c02218",
   "metadata": {},
   "source": [
    "Now we will start making our model. We will make two models, where in the first model we will use all the dependent variables from the CSV, and in the second model, we will use only: the '__Pclass__', '__Age__' and the '__male__' column. We will score the two models according to their __accuracy__, __precision__, __recall__ and __f1 score__. \n",
    "\n",
    "Note: The __F1 score__ is the harmonic mean of __precision__ and __recall__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51bb713-55a6-482f-a3e8-3fd8aa60eb22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Scores:\n",
      " 1) Accuracy: 81.0%\n",
      " 2) Precision: 79.0%\n",
      " 3) Recall: 67.0%\n",
      " 4) F1_score: 73.0% \n",
      "\n",
      "Model 2 Scores:\n",
      " 1) Accuracy: 82.0%\n",
      " 2) Precision: 81.0%\n",
      " 3) Recall: 67.0%\n",
      " 4) F1_score: 74.0%\n"
     ]
    }
   ],
   "source": [
    "# Creating the first model with all the variables:\n",
    "\n",
    "x = df.drop('Survived', axis= 'columns').values\n",
    "y = df['Survived'].values\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( x,y, \n",
    "                                                     test_size= 0.3, \n",
    "                                                     random_state= 5\n",
    "                                                     )\n",
    "\n",
    "model_1 = LogisticRegression()\n",
    "model_1.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model_1.predict(x_test)\n",
    "\n",
    "# Printing the scores of the first model:\n",
    "\n",
    "print(\"Model 1 Scores:\")\n",
    "print(f\" 1) Accuracy: {round(accuracy_score(y_test, y_pred), 2) * 100}%\") \n",
    "print(f\" 2) Precision: {round(precision_score(y_test, y_pred), 2) * 100}%\")\n",
    "print(f\" 3) Recall: {round(recall_score(y_test, y_pred), 2) * 100}%\")\n",
    "print(f\" 4) F1_score: {round(f1_score(y_test, y_pred), 2) * 100}% \\n\")\n",
    "\n",
    "# Creating the second model with only the 'Pclass', 'Age' and the 'male' column:\n",
    "\n",
    "X = df[['Pclass', 'Age', 'male']].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X,y, \n",
    "                                                     test_size= 0.3, \n",
    "                                                     random_state= 5\n",
    "                                                     )\n",
    "\n",
    "model_2 = LogisticRegression()\n",
    "model_2.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = model_2.predict(X_test)\n",
    "\n",
    "# Printing the scores of the second model:\n",
    "\n",
    "print(\"Model 2 Scores:\")\n",
    "print(f\" 1) Accuracy: {round(accuracy_score(Y_test, Y_pred), 2) * 100}%\")             \n",
    "print(f\" 2) Precision: {round(precision_score(Y_test, Y_pred), 2) * 100}%\")\n",
    "print(f\" 3) Recall: {round(recall_score(Y_test, Y_pred), 2) * 100}%\")\n",
    "print(f\" 4) F1_score: {round(f1_score(Y_test, Y_pred), 2) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad2743-f989-4eaf-b06f-f9bc210135b8",
   "metadata": {},
   "source": [
    "As we can see the second model has a good precision score than the first model. As our end goal is to make a model with the highest precision score, the second model should be our preferred model right away.\n",
    "\n",
    "However, with a __Logistic Regression__ model, we have an easy way of shifting between emphasizing precision and emphasizing recall. As the model dosen't just return a prediction, but it returns a probability value between 0 and 1 of all the datapoints. Typically if the value is __>= 0.5__, it predicts that the passenger survived, anything below it and it predicts that the passenger didn't survive. By tweaking this __threshold__ of __0.5__ we could increase or decrease the precision of the model. Therefore we will try to change the threshold and see if we could increase the precision of the second model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf17a348-2fab-4cf8-8cef-c0fa2a4b0103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91360539, 0.08639461],\n",
       "       [0.91360539, 0.08639461],\n",
       "       [0.92420319, 0.07579681],\n",
       "       [0.90417954, 0.09582046],\n",
       "       [0.91799671, 0.08200329]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the probability values of X_test:\n",
    "\n",
    "Y_pred_proba = model_2.predict_proba(X_test)\n",
    "\n",
    "Y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6528d51-af56-4a47-a82f-d3fb83157b4b",
   "metadata": {},
   "source": [
    "The method \"__predict_proba__\" of the Sklearn library gives us two values for each data point. The first value is the probability that the datapoint is in the __0__ class (__didn't survive__) and the second is the probability that the datapoint is in the __1__ class (__did survive__). We only need the second column of this result. Now we need to find a suitable __threshold__ that will give us the best __precision score__. In this regard, anything closer to __1__ will always be the best. But it will lower the recall rate significantly. Thus, instead of finding from probability value __0 to 1__, we will find the __threshold__ from __0 to 0.8__. That will give some room to __recall__.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04fac43-0c20-432f-a58b-08123a91e3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      " 1) Best threshold = 0.725\n",
      " 2) Best Precision Score = 94.0%\n"
     ]
    }
   ],
   "source": [
    "# Applying threshold tp positive probabilities to crate labels:\n",
    "\n",
    "def to_labels(possible_probs, thresholds):\n",
    "    return (possible_probs >= thresholds).astype('int')\n",
    "\n",
    "# Defining thresholds:\n",
    "\n",
    "thresholds = arange(0, 0.80, 0.001)\n",
    "\n",
    "# Evaluating each threshold:\n",
    "\n",
    "scores = [precision_score( Y_test,\n",
    "                           to_labels(Y_pred_proba[:,1], t),\n",
    "                           zero_division= 1\n",
    "                           )\n",
    "          for t in thresholds]\n",
    "\n",
    "# Getting the best threshold:\n",
    "\n",
    "ix = argmax(scores)\n",
    "\n",
    "print(\"Result:\")\n",
    "print(f\" 1) Best threshold = {thresholds[ix]}\")\n",
    "print(f\" 2) Best Precision Score = {round(scores[ix], 2) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2bec6-0b34-4d48-a7ec-ed78f41108be",
   "metadata": {},
   "source": [
    "We have got the best __threshold__ value and it enables us to get the highest __precision score__ possible. If we compare the positive probabilities from '__X_test__' to our __threshold__, we make sure that only the values equal to or greater than our __threshold__ get a '__True__'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f1eb16-2082-4372-9209-777ab8377e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing these probability values with our threshold:\n",
    "\n",
    "Y_pred_proba = model_2.predict_proba(X_test)[:,1] >= thresholds[ix]\n",
    "\n",
    "Y_pred_proba[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e4606-af9b-438a-9e7e-21a7407f2ce7",
   "metadata": {},
   "source": [
    "Now we will score the second model again in terms of __precision__ and __recall__. And compare it with the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5299b9b5-50e2-4e2a-bd0b-bd0f570ffde1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before increasung the threshold:\n",
      " 1) Precision: 81.0%\n",
      " 2) Recall: 67.0% \n",
      "\n",
      "After increasung the threshold:\n",
      " 1) Precision: 94.0%\n",
      " 2) Recall: 45.0%\n"
     ]
    }
   ],
   "source": [
    "# Score before tweaking the threshold:\n",
    "\n",
    "print(\"Before increasung the threshold:\")\n",
    "print(f\" 1) Precision: {round(precision_score(Y_test, Y_pred), 2) * 100}%\")\n",
    "print(f\" 2) Recall: {round(recall_score(Y_test, Y_pred), 2) * 100}% \\n\")\n",
    "\n",
    "# Score after tweaking the threshold:\n",
    "\n",
    "print(\"After increasung the threshold:\")\n",
    "print(f\" 1) Precision: {round(precision_score(Y_test, Y_pred_proba), 2)* 100}%\")\n",
    "print(f\" 2) Recall: {round(recall_score(Y_test, Y_pred_proba), 2) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3865845-d530-4c19-8e11-f49f9a9328c7",
   "metadata": {},
   "source": [
    "As we can see the precision of the model increased quite a lot. We will now try to predict the survival of three imaginary passengers: One a female at the age of 24 travelling in 1st class, second a boy at the age of 15, also travelling in 1st class, and an old man of 60 travelling in the 2nd class. We will create a new model that will be trained on the entire dataset rather than just __X_train__ and __Y_train__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "274a4aa2-139f-43c7-85fb-fd10fbe54738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did they survived?\n",
      " 1st passenger - True\n",
      " 2nd passenger - False\n",
      " 3rd passenger - False\n"
     ]
    }
   ],
   "source": [
    "# Creating a new Logistic Regression model:\n",
    "\n",
    "new_model = LogisticRegression()\n",
    "new_model.fit(X,y)\n",
    "\n",
    "# Using the dependent variables to predict an outcome:\n",
    "\n",
    "''' The code goes like this:\n",
    "\n",
    "        1st passenger -\n",
    "            'Pclass' = 1,\n",
    "            'Age' = 24,\n",
    "            'male' = 0 \n",
    "        \n",
    "        2nd passenger -\n",
    "            'Pclass' = 1,\n",
    "            'Age' = 15,\n",
    "            'male' = 1 \n",
    "            \n",
    "        3rd passenger -\n",
    "            'Pclass' = 2,\n",
    "            'Age' = 60,\n",
    "            'male' = 1 '''\n",
    "\n",
    "result = new_model.predict_proba([ [1,24,0], \n",
    "                                   [1,15,1], \n",
    "                                   [2,60,1] \n",
    "                                   ])[:,1] >= thresholds[ix]\n",
    "\n",
    "# Printing the results:\n",
    "\n",
    "print(\"Did they survived?\")\n",
    "print(f\" 1st passenger - {result[0]}\")\n",
    "print(f\" 2nd passenger - {result[1]}\")\n",
    "print(f\" 3rd passenger - {result[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1cf60e-4ae3-4e59-b1ce-aadefec46812",
   "metadata": {},
   "source": [
    "As we have increased the __precision__ of the model, whoever it has labelled '__Survived__' has more surety of survival now than in the normal model. \n",
    "\n",
    "\n",
    "__- by Sourin Das__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
